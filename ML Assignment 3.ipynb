{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d0b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT CUSTOMER CHURN IN A BANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413e2a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.5-cp39-none-win_amd64.whl (73.9 MB)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (1.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.2-py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (3.4.3)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.7.0-py2.py3-none-any.whl (28.8 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.0.5 graphviz-0.19.2 plotly-5.7.0 tenacity-8.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c56383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "329af531",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9024/1018461945.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#load necccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6de821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "churn = pd.read_csv('banking_churn.csv')\n",
    "data = churn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df62c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check size of the observation and variable\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the first 5 data in the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load columns in the datasets\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load information about the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb48e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing data\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e796ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis = 1 , inplace = True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics of the data\n",
    "stats = data.describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing target variable\n",
    "plt.figure(figsize = (15,8))\n",
    "sns.countplot('Exited', data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58985973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing how categorical data relates with the target variable (exited)\n",
    "cat_data = data[['Gender', 'Tenure','Geography', 'NumOfProducts', 'HasCrCard', 'IsActiveMember']]\n",
    "\n",
    "def categorical(var):\n",
    "    print(data[var].value_counts())\n",
    "    \n",
    "    plt.figure(figsize = (15,8))\n",
    "    sns.countplot(x = var, data = data, hue = 'Exited')\n",
    "    plt.show()\n",
    "    \n",
    "for i in cat_data:\n",
    "    categorical(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19332b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing numerical data\n",
    "Num_data = data[[ 'CreditScore', 'Age', 'Balance', 'EstimatedSalary' ]]\n",
    "def numerical(var):\n",
    "\n",
    "    plt.hist(data[var], bins = 20, color = \"brown\")\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"{} variable distribution\".format(var))\n",
    "    plt.show()\n",
    "    \n",
    "for i in Num_data:\n",
    "    numerical(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea801b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing outliers \n",
    "listOrder = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "\n",
    "def viz_outliers(var):\n",
    "\n",
    "    sns.boxplot(data[var])\n",
    "    plt.show()\n",
    "    \n",
    "for i in listOrder:\n",
    "    viz_outliers(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da605034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations\n",
    "# There is presence of outliers in CreditScore, Age, NumOfProducts\n",
    "outliers = ['Age','CreditScore','NumOfProducts']\n",
    "\n",
    "# create a function to remove the outliers\n",
    "def outlier_removal(data,column):\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    point_low = q1 - 1.5 * iqr\n",
    "    point_high = q3 + 1.5 * iqr\n",
    "    cleaned_data = data.loc[(data[column] >  point_low) & (data[column] <  point_high)]\n",
    "    return cleaned_data\n",
    "\n",
    "# clean the dataset by removing outliers\n",
    "data_cleaned = outlier_removal(outlier_removal(outlier_removal(data,'Age'),'CreditScore'),'NumOfProducts')\n",
    "\n",
    "print(data.shape)\n",
    "print(data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix \n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "list_corr = ['CreditScore' ,'Age' ,'Tenure' ,'Balance' ,'NumOfProducts' ,'EstimatedSalary' ,'Exited']\n",
    "sns.heatmap(data_cleaned[list_corr].corr(), annot = True, linecolor = \"green\", lw = 0.5, fmt= '.2f') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Observation\n",
    "# Age has the strongest relation with Exited (0.36).\n",
    "#   As the age of the customer increases, the rate of losing the customer increases. (Positive strong relationship)\n",
    "# Exited and Balance variable have a relatively strong relationship (0.11).\n",
    "# Exited and the variable NumOfProducts have a moderately strong relationship (-0.11).\n",
    "#  They have a strong negative relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46901b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing how numerical variable relates with the target variable (exited)\n",
    "# AGE AND EXIT\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "sns.lineplot(x = \"Age\", y = \"Exited\", data = data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8516c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.groupby(data_cleaned[\"Exited\"])[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489aed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation\n",
    "# As the age of the customer increases, the customer losing rate increases.\n",
    "# Average age of customers who did not leave the bank is 36\n",
    "# Average age of customers leaving the bank is 43\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ac16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# since geography is a categorical data lets one-hot encode it by using pd.get_dummies\n",
    "data_cleaned = pd.get_dummies(data_cleaned, columns = ['Geography'])\n",
    "\n",
    "# since gender is a categorical data lets label encode it as female = 1 and male = 0\n",
    "def func(data_cleaned):\n",
    "    d =[]\n",
    "    for m in data_cleaned:\n",
    "        if m =='Female':\n",
    "            d.append(1)\n",
    "        else:\n",
    "            d.append(0)\n",
    "    return d\n",
    "\n",
    "data_cleaned['Gender'] = func(data_cleaned['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf686c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237cd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79470d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling.\n",
    "\n",
    "x = data_cleaned.drop('Exited', axis = 1) \n",
    "y = data_cleaned['Exited']\n",
    "\n",
    "#splitting data into test and train set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2986a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d249878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression() # algorithm instantiation\n",
    "Lr.fit(x_train, y_train) # model learning\n",
    "\n",
    "# make your predictions on the test data\n",
    "pred = Lr.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "\n",
    "# evaluate the test data using accuracy score\n",
    "print(\"Accuracy score of Logistic Regression model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d24160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform feature scaling (standardization) using standardscalar()\n",
    "sc = StandardScaler()\n",
    "xstandard_train = sc.fit_transform(x_train)\n",
    "xstandard_test = sc.transform (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a46c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr_s = LogisticRegression() # algorithm instantiation\n",
    "Lr_s.fit(xstandard_train, y_train)\n",
    "\n",
    "pred = Lr_s.predict(xstandard_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "Lr_score = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy score of Standardised Logistic Regression model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d73fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "\n",
    "svc = SVC(probability = True) # algorithm instantiation\n",
    "svc.fit(xstandard_train, y_train)\n",
    "\n",
    "pred = svc.predict(xstandard_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "svc_score = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy score of SVC model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5) # algorithm instantiation\n",
    "knn.fit(xstandard_train, y_train)\n",
    "\n",
    "pred = knn.predict(xstandard_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "knn_score = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy score of KNN model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c47b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363988c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "rand = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "rand.fit(x_train, y_train)\n",
    "pred = rand.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "rand_score = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy score of Random Forest model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc09f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = RandomForestClassifier(random_state = 42, max_depth = 10, n_estimators = 1000)\n",
    "\n",
    "rand.fit(x, y)\n",
    "\n",
    "scoreRand = cross_val_score(rand, x, y, cv=5, scoring='accuracy')\n",
    "print ('The mean value of cross val score is {}'.format(scoreRand.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0fee15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "\n",
    "xgb =XGBClassifier(learning_rate=0.01,n_estimators=200, \n",
    "                            max_depth=5, eval_metric=\"logloss\")\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "pred = xgb.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "xgb_score = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy score of XGB model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =XGBClassifier()\n",
    "xgb.fit(x, y)\n",
    "\n",
    "scoreXGB = cross_val_score(xgb, x, y, cv=10, scoring='accuracy')\n",
    "print ('The mean value of cross val score is {}'.format(scoreXGB.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7aa131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "\n",
    "model_grb = GradientBoostingClassifier()\n",
    "\n",
    "model_grb.fit(x_train,y_train)\n",
    "\n",
    "pred = model_grb.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "grb_score = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy score of Gradient Boost model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61397fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grb = GradientBoostingClassifier()\n",
    "model_grb.fit(x, y)\n",
    "\n",
    "scoreGRB = cross_val_score(model_grb, x, y, cv=10, scoring='accuracy')\n",
    "print ('The mean value of cross val score is {}'.format(scoreGRB.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a804f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM_Model\n",
    "\n",
    "lgbm_model = LGBMClassifier(silent = 0, learning_rate = 0.09, max_delta_step = 2, n_estimators = 100, boosting_type = 'gbdt',\n",
    "                            max_depth = 10, eval_metric = \"logloss\", gamma = 3, base_score = 0.5)\n",
    "\n",
    "lgbm_model.fit(x_train, y_train)\n",
    "y_pred = lgbm_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, digits=2))\n",
    "lgbm_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score of tuned LightGBM model: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7878b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6994f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostClassifier\n",
    "\n",
    "#Instantiate CatBoostClassifier\n",
    "catboost = CatBoostClassifier()\n",
    "\n",
    "#create the grid\n",
    "grid = {'max_depth': [3,4,5],'n_estimators':[100, 200, 300]}\n",
    "\n",
    "#Instantiate GridSearchCV\n",
    "gscv = GridSearchCV (estimator = catboost, param_grid = grid, scoring ='accuracy', cv = 5)\n",
    "\n",
    "#fit the model\n",
    "gscv.fit(x_train,y_train)\n",
    "\n",
    "#returns the estimator with the best performance\n",
    "print(gscv.best_estimator_)\n",
    "\n",
    "#returns the best score\n",
    "print(gscv.best_score_)\n",
    "\n",
    "#returns the best parameters\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783286ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(max_depth = 4, n_estimators = 200 , verbose=0)\n",
    "\n",
    "cat.fit(x_train, y_train)\n",
    "pred = cat.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred, digits=2))\n",
    "cat_score = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy score of CatBoost model: \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(max_depth=4, n_estimators=1000, verbose=0)\n",
    "\n",
    "cat_tuned = cat.fit(x, y)\n",
    "scoreCat = cross_val_score(cat, x, y, cv=5, scoring='accuracy')\n",
    "print ('The mean value of cross val score is {}'.format(scoreCat.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0672b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMSEMBLE\n",
    "model = VotingClassifier(estimators=[('catboost', cat), ('LGBM', lgbm_model), ('GradientBoost', model_grb), ('randomforest', rand)], voting='hard')\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data =[['LightGBM Classifier', lgbm_score],\n",
    "             ['Random Forest Classifier', rand_score],\n",
    "             ['Catboost Classifier', cat_score], \n",
    "             ['XGB Classifier', xgb_score],\n",
    "             ['Gradient Boost Classifier', grb_score],\n",
    "             ['SVM Classifier', svc_score],\n",
    "             ['Logistic Regression', Lr_score],\n",
    "             ['KNN Classifier', knn_score]] \n",
    "\n",
    "indexes = [1,2,3,4,5,6,7,8]\n",
    "columns_name = ['MODEL', 'ACCURACY_SCORE']\n",
    "fmw = pd.DataFrame(data = model_data,index = indexes, columns = columns_name )\n",
    "print(fmw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c94774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using Area under Curve to evaluate best performed model\n",
    "\n",
    "plot_roc_curve(cat, x_test, y_test) \n",
    "plot_roc_curve(rand, x_test, y_test) \n",
    "plot_roc_curve(model_grb, x_test, y_test)\n",
    "plot_roc_curve(svc, x_test, y_test) \n",
    "plot_roc_curve(knn, x_test, y_test) \n",
    "plot_roc_curve(Lr_s, x_test, y_test)\n",
    "plot_roc_curve(xgb, x_test, y_test) \n",
    "plot_roc_curve(lgbm_model, x_test, y_test) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary:\n",
    "# The best model amonst the ones implemented is Random Forests with an accuracy of 86.2%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance of random forest model i.e the most importance predictive feature (variables) in the model performance\n",
    "feature_index = data_cleaned.loc[:, x.columns ]\n",
    "\n",
    "feature_importance = pd.Series(rand.feature_importances_, \n",
    "                               index=feature_index.columns).sort_values(ascending=False)\n",
    "                               \n",
    "sns.barplot(x = feature_importance, y = feature_importance.index, color='brown')\n",
    "plt.xlabel('Variable Importance Scores')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment\n",
    "# saving the model \n",
    "import pickle \n",
    "pickle_out = open(\"classifier.pkl\", mode = \"wb\") \n",
    "pickle.dump(rand, pickle_out) \n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba243b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2958a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q streamlit_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1772459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    " \n",
    "import pickle\n",
    "import streamlit as st\n",
    " \n",
    "# loading the trained model\n",
    "pickle_in = open('classifier.pkl', 'rb') \n",
    "classifier = pickle.load(pickle_in)\n",
    " \n",
    "@st.cache()\n",
    "  \n",
    "# defining the function which will make the prediction using the data which the user inputs \n",
    "def prediction(CreditScore, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Geography_France, Geography_Germany, Geography_Spain):   \n",
    " \n",
    "    # Pre-processing user input    \n",
    "    if Gender == \"Male\":\n",
    "        Gender = 0\n",
    "    else:\n",
    "        Gender = 1\n",
    " \n",
    "    if HasCrCard == \"No\":\n",
    "        HasCrCard = 0\n",
    "    else:\n",
    "        HasCrCard = 1\n",
    " \n",
    "    if IsActiveMember == \"No\":\n",
    "        IsActiveMember = 0\n",
    "    else:\n",
    "        IsActiveMember = 1  \n",
    "\n",
    "    if Geography_France == \"Yes\":\n",
    "        Geography_France = 1\n",
    "    else:\n",
    "        Geography_France = 0\n",
    "\n",
    "    if Geography_Spain == \"Yes\":\n",
    "        Geography_Spain = 1\n",
    "    else:\n",
    "        Geography_Spain = 0\n",
    "    \n",
    "    if Geography_Germany == \"Yes\":\n",
    "        Geography_Germany = 1\n",
    "    else:\n",
    "        Geography_Germany = 0\n",
    "\n",
    " \n",
    "    # Making predictions \n",
    "    prediction = classifier.predict( \n",
    "        [[CreditScore, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Geography_France, Geography_Germany, Geography_Spain]])\n",
    "     \n",
    "    if prediction == 0:\n",
    "        pred = 'Stay!'\n",
    "    else:\n",
    "        pred = 'Leave!'\n",
    "    return pred\n",
    "\n",
    "\n",
    "# this is the main function in which we define our webpage  \n",
    "def main():       \n",
    "    # front end elements of the web page \n",
    "    html_temp = \"\"\" \n",
    "    <div style =\"background-color:brown;padding:13px\"> \n",
    "    <h1 style =\"color:gray1;text-align:center;\">Streamlit Bank Customer Churn Prediction MLApp</h1> \n",
    "    </div> \n",
    "    \"\"\"\n",
    "      \n",
    "    # display the front end aspect\n",
    "    st.markdown(html_temp, unsafe_allow_html = True) \n",
    "      \n",
    "    # following lines create boxes in which user can enter data required to make prediction \n",
    "    Gender = st.selectbox(\"Customer's Gender\",(\"Male\",\"Female\"))\n",
    "    Age = st.number_input(\"Customer's Age\")\n",
    "    NumOfProducts = st.selectbox(\"Total Number of Bank Product The Customer Uses\", (\"1\",\"2\",\"3\",\"4\"))\n",
    "    Tenure = st.selectbox(\"Number of Years The Customer Has Been a Client\", (\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"))\n",
    "    HasCrCard = st.selectbox('Does The Customer has a Credit Card?',(\"Yes\",\"No\"))\n",
    "    IsActiveMember = st.selectbox('Is The Customer an Active Member?',(\"Yes\",\"No\"))\n",
    "    EstimatedSalary = st.number_input(\"Estimated Salary of Customer\") \n",
    "    Balance = st.number_input(\"Customer's Account Balance\")\n",
    "    CreditScore = st.number_input(\"Customer's Credit Score\")\n",
    "    Geography_France = st.selectbox('Is the Customer From France?',(\"Yes\",\"No\"))\n",
    "    Geography_Spain = st.selectbox('Is the Customer From Spain?',(\"Yes\",\"No\"))\n",
    "    Geography_Germany = st.selectbox('Is the Customer From Germany?',(\"Yes\",\"No\"))\n",
    "\n",
    "    result =\"\"\n",
    "      \n",
    "    # when 'Predict' is clicked, make the prediction and store it \n",
    "    if st.button(\"Predict\"): \n",
    "        result = prediction(CreditScore, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Geography_France, Geography_Germany, Geography_Spain) \n",
    "        st.success('The Customer will {}'.format(result))\n",
    "        #print(LoanAmount)\n",
    "     \n",
    "if __name__=='__main__': \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py &>/dev/null&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8990340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    " \n",
    "public_url = ngrok.connect('8888')\n",
    "public_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323a7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
